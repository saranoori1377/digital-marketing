{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3d0f6d4-3273-49d6-b20b-644b1c0d209f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m df_mobile\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame(all_mobile_data)\n\u001b[0;32m     26\u001b[0m df_pc \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(all_pc_data)\n\u001b[1;32m---> 28\u001b[0m num_unique_pc \u001b[38;5;241m=\u001b[39m \u001b[43mdf_pc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mnunique()\n\u001b[0;32m     29\u001b[0m num_unique_mobile \u001b[38;5;241m=\u001b[39m df_mobile[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnunique()\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumber of pc model\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_unique_pc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\core\\indexes\\range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[1;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'name'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "pc_data = ['apple.json','acer.json', 'asus.json', 'hp.json', 'lenovo.json', 'msi.json']\n",
    "mobile_data = ['honor.json' , 'huawei.json' , 'nokia.json' , 'samsung.json', 'xiaomi.json']\n",
    "\n",
    "\n",
    "all_pc_data = []\n",
    "all_mobile_data=[]\n",
    "\n",
    "for filename in os.listdir():\n",
    "    if filename in pc_data:  \n",
    "        with open(filename, 'r', encoding='utf-8') as file:\n",
    "            data1 = json.load(file)\n",
    "            all_pc_data.append(data1) \n",
    "\n",
    "\n",
    "for filename in os.listdir():\n",
    "    if filename in mobile_data:  \n",
    "        with open(filename, 'r', encoding='utf-8') as file:\n",
    "            data2 = json.load(file)\n",
    "            all_mobile_data.append(data2) \n",
    "            \n",
    "df_mobile=pd.DataFrame(all_mobile_data)\n",
    "df_pc = pd.DataFrame(all_pc_data)\n",
    "\n",
    "num_unique_pc = df_pc['name'].nunique()\n",
    "num_unique_mobile = df_mobile['name'].nunique()\n",
    "\n",
    "print(f\"number of pc model': {num_unique_pc}\")\n",
    "print(f\"number of mobile model: {num_unique_pc}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c1d9f3e-3c36-4f5b-9c6b-2690d7c6adb7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, int found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m columns \u001b[38;5;241m=\u001b[39m df_pc\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# نمایش داده‌ها به همراه نام ستون‌ها به شکل جدول\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m | \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# چاپ نام ستون‌ها\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m array_data:\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m | \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mstr\u001b[39m, row)))\n",
      "\u001b[1;31mTypeError\u001b[0m: sequence item 0: expected str instance, int found"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# فرض اینکه df همان دیتافریم شما باشد\n",
    "# تبدیل 5 سطر اول به یک numpy array\n",
    "array_data = df_pc.head(5).to_numpy()\n",
    "\n",
    "# نمایش نام ستون‌ها\n",
    "columns = df_pc.columns\n",
    "\n",
    "# نمایش داده‌ها به همراه نام ستون‌ها به شکل جدول\n",
    "print(f\"{' | '.join(columns)}\")  # چاپ نام ستون‌ها\n",
    "for row in array_data:\n",
    "    print(\" | \".join(map(str, row)))  # چاپ هر سطر\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b76b2f7f-87c5-4ff3-a2b1-1035f83c956d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all pc data: 1017\n",
      "0    7.237900e+08\n",
      "1    1.931890e+09\n",
      "2    1.228999e+09\n",
      "3    1.221000e+09\n",
      "4    1.321099e+09\n",
      "Name: price, dtype: float64\n",
      "Number of all mobile data: 884\n",
      "0    7.237900e+08\n",
      "1    1.931890e+09\n",
      "2    1.228999e+09\n",
      "3    1.221000e+09\n",
      "4    1.321099e+09\n",
      "Name: price, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def persian_to_english_numbers(s):\n",
    "    numbers = {'۰': '0', '۱': '1', '۲': '2', '۳': '3', '۴': '4',\n",
    "               '۵': '5', '۶': '6', '۷': '7', '۸': '8', '۹': '9'}\n",
    "    if isinstance(s, str): \n",
    "        for persian_digit, english_digit in numbers.items():\n",
    "            s = s.replace(persian_digit, english_digit)\n",
    "    return s\n",
    "\n",
    "\n",
    "if all_pc_data:\n",
    "    dfs1 = [pd.DataFrame(data1) for data1 in all_pc_data]\n",
    "    combined_df1 = pd.concat(dfs1, ignore_index=True)\n",
    "    print(f\"Number of all pc data: {len(combined_df1)}\")\n",
    "    combined_df1['price'] = combined_df1['price'].apply(persian_to_english_numbers)\n",
    "    combined_df1['price'] = combined_df1['price'].str.replace(r'[٪,]', '', regex=True)\n",
    "    combined_df1['price'] = pd.to_numeric(combined_df1['price'], errors='coerce')  # تبدیل به نوع عددی\n",
    "    print(combined_df1['price'].head(5))\n",
    "else:\n",
    "    print(\"No data has been loaded\")\n",
    "\n",
    "if all_mobile_data:\n",
    "    dfs2 = [pd.DataFrame(data2) for data2 in all_mobile_data]\n",
    "    combined_df2 = pd.concat(dfs2, ignore_index=True)\n",
    "    print(f\"Number of all mobile data: {len(combined_df2)}\")\n",
    "    combined_df2['price'] = combined_df2['price'].apply(persian_to_english_numbers)\n",
    "    combined_df2['price'] = combined_df2['price'].str.replace(r'[٪,]', '', regex=True)\n",
    "    combined_df2['price'] = pd.to_numeric(combined_df2['price'], errors='coerce')  # تبدیل به نوع عددی\n",
    "    print(combined_df1['price'].head(5))\n",
    "else:\n",
    "    print(\"No data has been loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d50b4696-0160-45ee-96f0-38a661559a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   rate\n",
      "0   4.8\n",
      "1   4.7\n",
      "2   NaN\n",
      "3   NaN\n",
      "4   5.0\n",
      "   rate\n",
      "0   4.4\n",
      "1   4.5\n",
      "2   4.5\n",
      "3   4.2\n",
      "4   4.4\n"
     ]
    }
   ],
   "source": [
    "# swich number to english for pc data\n",
    "combined_df1['rate'] = combined_df1['rate'].apply(persian_to_english_numbers)\n",
    "combined_df1['rate'] = pd.to_numeric(combined_df1['rate'], errors='coerce')  \n",
    "print(combined_df1[['rate']].head(5))\n",
    "\n",
    "# swich number to english for mobile data\n",
    "combined_df2['rate'] = combined_df2['rate'].apply(persian_to_english_numbers)\n",
    "combined_df2['rate'] = pd.to_numeric(combined_df2['rate'], errors='coerce')  \n",
    "print(combined_df2[['rate']].head(5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "932d014a-df1a-4e1d-a22b-b54902bd4ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values in 'rate' for pc data: 442\n",
      "Number of NaN values in 'price' for pc data: 368\n",
      "Number of NaN values in 'rate' for mobile data: 63\n",
      "Number of NaN values in 'price' for mobile data: 684\n"
     ]
    }
   ],
   "source": [
    "# محاسبه تعداد مقادیر NaN در ستون‌های 'rate' و 'price'\n",
    "nan_rate_pc = combined_df1['rate'].isna().sum()\n",
    "nan_price_pc = combined_df1['price'].isna().sum()\n",
    "\n",
    "nan_rate_mobile = combined_df2['rate'].isna().sum()\n",
    "nan_price_mobile = combined_df2['price'].isna().sum()\n",
    "\n",
    "print(f\"Number of NaN values in 'rate' for pc data: {nan_rate_pc}\")\n",
    "print(f\"Number of NaN values in 'price' for pc data: {nan_price_pc}\")\n",
    "\n",
    "print(f\"Number of NaN values in 'rate' for mobile data: {nan_rate_mobile}\")\n",
    "print(f\"Number of NaN values in 'price' for mobile data: {nan_price_mobile}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62c45176-2407-419e-91bd-f1e4b7e0cdb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 name         price\n",
      "0   لپ تاپ 15.6 اینچی ایسر مدل Aspire 3 A315-58G-i...  7.237900e+08\n",
      "1   لپ تاپ 15.6 اینچی ایسر مدل Aspire 7 A715-42G-R2YB  1.931890e+09\n",
      "2   لپ تاپ 15.6 اینچی ایسر مدل Aspire 3 A315-58G-7...  1.228999e+09\n",
      "3   لپ تاپ 15.6 اینچی ایسر مدل Aspire A315-23-R3PE...  1.221000e+09\n",
      "4   لپ تاپ 15.6 اینچی ایسر مدل Aspire 3 A315-58G-3...  1.321099e+09\n",
      "5   لپ تاپ 15.6 اینچی ایسر مدل Nitro 5 AN515-57-79...  1.246699e+09\n",
      "6    لپ تاپ 17.3 اینچی ایسر مدل Nitro 5 AN517-55-57WA  5.413900e+08\n",
      "7   لپ تاپ 15.6 اینچی ایسر مدل Aspire A315-23-R3PE...  2.121764e+09\n",
      "8   لپ تاپ 15.6 اینچی ایسر مدل Aspire 3 A315-58G-3...  2.020099e+09\n",
      "9      لپ تاپ 15 اینچی ایسر مدل Nitro 5 AN515-57-59WQ  3.038900e+09\n",
      "10  لپ تاپ 15.6 اینچی ایسر مدل TravelMate P2 TMP21...  2.710000e+07\n",
      "11  لپ تاپ 15.6 اینچی ایسر مدل Nitro 5 AN515-58-75...  1.051199e+09\n",
      "12  لپ تاپ 15.6 اینچی ایسر مدل Nitro 5 AN515-57-79...  1.345099e+09\n",
      "13  لپ تاپ 15.6 اینچی ایسر مدل Aspire 3 A315-58G-7...  1.129499e+09\n",
      "14  لپ تاپ 15.6 اینچی ایسر مدل Aspire 3 A315-58G-7...  1.228999e+09\n"
     ]
    }
   ],
   "source": [
    "#   محاسبه میانگین قیمت برای هر مدل\n",
    "mean_prices = combined_df.groupby('name')['price'].mean()\n",
    "\n",
    "def fill_missing_price(row):\n",
    "    if pd.isna(row['price']):\n",
    "        return mean_prices[row['name']] \n",
    "    return row['price']\n",
    "\n",
    "combined_df['price'] = combined_df.apply(fill_missing_price, axis=1)\n",
    "print(combined_df[['name', 'price']].head(15\n",
    "                                         ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d49d752-765b-472b-9393-e2e3dd7160b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
